{"cells":[{"cell_type":"markdown","id":"lQMN7B5FKR2S","metadata":{"id":"lQMN7B5FKR2S"},"source":["\n","<center><font size=6>Introduction to Prompt Engineering</center></font>"]},{"cell_type":"markdown","id":"HxgFkEuv1raU","metadata":{"id":"HxgFkEuv1raU"},"source":["<center><font size=6>Restaurant Review Analysis</center></font>"]},{"cell_type":"markdown","id":"G-jLkpBYdP89","metadata":{"id":"G-jLkpBYdP89"},"source":["## Problem Statement"]},{"cell_type":"markdown","id":"xClk0SOxdU_s","metadata":{"id":"xClk0SOxdU_s"},"source":["### Business Context"]},{"cell_type":"markdown","id":"cPfUxkrbQpmc","metadata":{"id":"cPfUxkrbQpmc"},"source":["The company receives large volumes of customer reviews across its restaurants. These reviews contain valuable insights that can guide business and marketing decisions."]},{"cell_type":"markdown","id":"MzSKXh2LsOvd","metadata":{"id":"MzSKXh2LsOvd"},"source":["### Problem Definition"]},{"cell_type":"markdown","id":"my--X4VNQsPd","metadata":{"id":"my--X4VNQsPd"},"source":["Manual analysis of unstructured text reviews is slow and unscalable.\n","The company struggles to automatically extract and understand customer sentiments (positive, negative, or neutral) from this data."]},{"cell_type":"markdown","id":"mgGZFBqvdX3_","metadata":{"id":"mgGZFBqvdX3_"},"source":["### Objective"]},{"cell_type":"markdown","id":"5Q0UjpRLUteW","metadata":{"id":"5Q0UjpRLUteW"},"source":["Build an automated sentiment analysis model using an LLM to predict customer sentiment, enabling data-driven insights and improved customer satisfaction."]},{"cell_type":"markdown","id":"b8pDl8uVKR2W","metadata":{"id":"b8pDl8uVKR2W"},"source":["## Installing and Importing Necessary Libraries"]},{"cell_type":"code","execution_count":null,"id":"fN9ATQxwKR2W","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fN9ATQxwKR2W","outputId":"fbf7ab48-4c5f-490d-9f95-22c841fb7709","executionInfo":{"status":"ok","timestamp":1761541031761,"user_tz":-330,"elapsed":8607,"user":{"displayName":"Gauravi","userId":"01757174725300251411"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n","\u001b[0m^C\n"]}],"source":["# Installation for GPU llama-cpp-python\n","# uncomment and run the following code in case GPU is being used\n","!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip install llama-cpp-python==0.2.45 --force-reinstall --no-cache-dir -q\n","\n","# Installation for CPU llama-cpp-python\n","# uncomment and run the following code in case GPU is not being used\n","# !CMAKE_ARGS=\"-DLLAMA_CUBLAS=off\" FORCE_CMAKE=1 pip install llama-cpp-python==0.2.45 --force-reinstall --no-cache-dir -q"]},{"cell_type":"markdown","id":"4f7QF-gRUmrL","metadata":{"id":"4f7QF-gRUmrL"},"source":["**Note**: pip's dependency error can be ignored as it does not affect further execution."]},{"cell_type":"code","execution_count":null,"id":"VFjHLA6SKR2W","metadata":{"id":"VFjHLA6SKR2W","colab":{"base_uri":"https://localhost:8080/","height":321},"executionInfo":{"status":"error","timestamp":1761541033187,"user_tz":-330,"elapsed":1215,"user":{"displayName":"Gauravi","userId":"01757174725300251411"}},"outputId":"d5d4f5e4-c171-4101-907c-19c52292bdac"},"outputs":[{"output_type":"stream","name":"stdout","text":["^C\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3841413675.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# For downloading the models from HF Hub\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install huggingface_hub==0.20.3 -q'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m       \u001b[0m_pip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_previous_import_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_send_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_pip.py\u001b[0m in \u001b[0;36mprint_previous_import_warning\u001b[0;34m(output)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprint_previous_import_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m   \u001b[0;34m\"\"\"Prints a warning about previously imported packages.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m   \u001b[0mpackages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_previously_imported_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpackages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# display a list of packages using the colab-display-data mimetype, which\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_pip.py\u001b[0m in \u001b[0;36m_previously_imported_packages\u001b[0;34m(pip_output)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_previously_imported_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpip_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m   \u001b[0;34m\"\"\"List all previously imported packages from a pip install.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m   \u001b[0minstalled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_extract_toplevel_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpip_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstalled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_pip.py\u001b[0m in \u001b[0;36m_extract_toplevel_packages\u001b[0;34m(pip_output)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;34m\"\"\"Extract the list of toplevel packages associated with a pip install.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0mtoplevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mps\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpackages_distributions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m       \u001b[0mtoplevel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mpackages_distributions\u001b[0;34m()\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdistributions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpkg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_top_level_declared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_top_level_inferred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m             \u001b[0mpkg_to_dist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpkg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkg_to_dist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mmetadata\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    450\u001b[0m         )\n\u001b[1;32m    451\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_adapters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memail\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage_from_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/email/__init__.py\u001b[0m in \u001b[0;36mmessage_from_string\u001b[0;34m(s, *args, **kws)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \"\"\"\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0memail\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mParser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparsestr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmessage_from_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/email/parser.py\u001b[0m in \u001b[0;36mparsestr\u001b[0;34m(self, text, headersonly)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mthe\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \"\"\"\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStringIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheadersonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheadersonly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/email/parser.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, fp, headersonly)\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mfeedparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_headersonly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m:=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8192\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mfeedparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfeedparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/email/feedparser.py\u001b[0m in \u001b[0;36mfeed\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;34m\"\"\"Push more data into the parser.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/email/feedparser.py\u001b[0m in \u001b[0;36mpush\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;31m# Crack into lines, preserving the linesep characters.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_partial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_partial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_partial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_partial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# For downloading the models from HF Hub\n","!pip install huggingface_hub==0.20.3 -q"]},{"cell_type":"code","execution_count":null,"id":"9ad4a052","metadata":{"id":"9ad4a052"},"outputs":[],"source":["# Importing library for data manipulation\n","import pandas as pd\n","import json"]},{"cell_type":"code","execution_count":null,"id":"0b8a3ac5-6a89-4dca-931c-3d252dee9322","metadata":{"id":"0b8a3ac5-6a89-4dca-931c-3d252dee9322"},"outputs":[],"source":["import pandas as pd"]},{"cell_type":"code","execution_count":null,"id":"mOyQTXjGVZzW","metadata":{"id":"mOyQTXjGVZzW"},"outputs":[],"source":["# Importing library for data manipulation\n","import pandas as pd\n","\n","# Function to download the model from the Hugging Face model hub\n","from huggingface_hub import hf_hub_download\n","\n","# Importing the Llama class from the llama_cpp module\n","from llama_cpp import Llama\n","\n","# Importing the json module\n","import json"]},{"cell_type":"markdown","id":"mv_4wV7dTNqQ","metadata":{"id":"mv_4wV7dTNqQ"},"source":["## Import the dataset"]},{"cell_type":"code","execution_count":null,"id":"TfpwypirdmDT","metadata":{"id":"TfpwypirdmDT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"error","timestamp":1761541176529,"user_tz":-330,"elapsed":121429,"user":{"displayName":"Gauravi","userId":"01757174725300251411"}},"outputId":"0d40cb2a-2ef1-408d-b26d-a0dce719f52a"},"outputs":[{"output_type":"error","ename":"ValueError","evalue":"mount failed","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1408506528.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         )\n\u001b[0;32m--> 272\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: mount failed"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"id":"zb2dDd4ekE_V","metadata":{"id":"zb2dDd4ekE_V"},"outputs":[],"source":["data = pd.read_csv(\"restaurant_reviews.csv\")"]},{"cell_type":"markdown","id":"H-51wMmpGzcr","metadata":{"id":"H-51wMmpGzcr"},"source":["## Data Overview"]},{"cell_type":"code","execution_count":null,"id":"NA2wS2mVkK7X","metadata":{"id":"NA2wS2mVkK7X"},"outputs":[],"source":["# checking the first five rows of the data\n","data.head()"]},{"cell_type":"code","execution_count":null,"id":"e6fcfcf5","metadata":{"id":"e6fcfcf5"},"outputs":[],"source":["data['review_full'][3]"]},{"cell_type":"code","execution_count":null,"id":"m0E69LFPThSJ","metadata":{"id":"m0E69LFPThSJ"},"outputs":[],"source":["# checking the shape of the data\n","data.shape"]},{"cell_type":"markdown","id":"udY09oFqTm1B","metadata":{"id":"udY09oFqTm1B"},"source":["**Observations**\n","\n","- Data has 20 rows and 3 columns"]},{"cell_type":"code","execution_count":null,"id":"qMV8hC_2G9aW","metadata":{"id":"qMV8hC_2G9aW"},"outputs":[],"source":["# checking for missing values\n","data.isnull().sum()"]},{"cell_type":"markdown","id":"8zETWVmeHBIk","metadata":{"id":"8zETWVmeHBIk"},"source":["**Observations**\n","\n","- There are no missing values in the data"]},{"cell_type":"markdown","id":"L5pIwimGK5_1","metadata":{"id":"L5pIwimGK5_1"},"source":["## Model Building"]},{"cell_type":"markdown","id":"jbaduRVymY3v","metadata":{"id":"jbaduRVymY3v"},"source":["### Loading the model (Llama)"]},{"cell_type":"code","execution_count":null,"id":"61N9i3i8K5_9","metadata":{"id":"61N9i3i8K5_9"},"outputs":[],"source":["model_name_or_path = \"TheBloke/Llama-2-13B-chat-GGUF\"\n","model_basename = \"llama-2-13b-chat.Q5_K_M.gguf\" # the model is in gguf format"]},{"cell_type":"code","execution_count":null,"id":"0ZpjCaMRVcM-","metadata":{"id":"0ZpjCaMRVcM-"},"outputs":[],"source":["# Using hf_hub_download to download a model from the Hugging Face model hub\n","# The repo_id parameter specifies the model name or path in the Hugging Face repository\n","# The filename parameter specifies the name of the file to download\n","model_path = hf_hub_download(\n","    repo_id=model_name_or_path,\n","    filename=model_basename)"]},{"cell_type":"code","execution_count":null,"id":"1SolgBhkVdgc","metadata":{"id":"1SolgBhkVdgc"},"outputs":[],"source":["lcpp_llm = Llama(\n","    model_path=model_path,\n","    n_threads=2,  # CPU cores\n","    n_batch=512,  # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.\n","    # n_gpu_layers=43,  # uncomment and change this value based on GPU VRAM pool.\n","    n_ctx=4096,  # Context window\n",")"]},{"cell_type":"markdown","id":"oWvf3R3An5K4","metadata":{"id":"oWvf3R3An5K4"},"source":["### Loading the model (Mistral)"]},{"cell_type":"code","execution_count":null,"id":"rF2F_YO_qGtV","metadata":{"id":"rF2F_YO_qGtV"},"outputs":[],"source":["model_name_or_path = \"TheBloke/Mistral-7B-Instruct-v0.2-GGUF\"\n","model_basename = \"mistral-7b-instruct-v0.2.Q6_K.gguf\""]},{"cell_type":"code","execution_count":null,"id":"Uk2q7vrc_TrO","metadata":{"id":"Uk2q7vrc_TrO"},"outputs":[],"source":["model_path = hf_hub_download(\n","    repo_id=model_name_or_path,\n","    filename=model_basename\n",")"]},{"cell_type":"code","execution_count":null,"id":"wI_T-0DWXRtD","metadata":{"id":"wI_T-0DWXRtD"},"outputs":[],"source":["llm = Llama(\n","    model_path=model_path,\n","    n_ctx=1024,\n",")"]},{"cell_type":"markdown","id":"VVXK7vYfmdkL","metadata":{"id":"VVXK7vYfmdkL"},"source":["### Defining Model Response Parameters"]},{"cell_type":"code","execution_count":null,"id":"5AfP0mcXVfXV","metadata":{"id":"5AfP0mcXVfXV"},"outputs":[],"source":["def generate_llama_response(instruction, review):\n","\n","    # System message explicitly instructing not to include the review text\n","    system_message = \"\"\"\n","        [INST]<<SYS>>\n","        {}\n","        <</SYS>>[/INST]\n","    \"\"\".format(instruction)\n","\n","    # Combine user_prompt and system_message to create the prompt\n","    prompt = f\"{review}\\n{system_message}\"\n","\n","    # Generate a response from the LLaMA model\n","    response = lcpp_llm(\n","        prompt=prompt,\n","        max_tokens=1024,\n","        temperature=0,\n","        top_p=0.95,\n","        repeat_penalty=1.2,\n","        top_k=50,\n","        stop=['INST'],\n","        echo=False,\n","        seed=42,\n","    )\n","\n","    # Extract the sentiment from the response\n","    response_text = response[\"choices\"][0][\"text\"]\n","    return response_text"]},{"cell_type":"markdown","id":"SMXvOtlrmHJC","metadata":{"id":"SMXvOtlrmHJC"},"source":["- **`max_tokens`**: This parameter **specifies the maximum number of tokens that the model should generate** in response to the prompt.\n","\n","- **`temperature`**: This parameter **controls the randomness of the generated response**. A higher temperature value will result in a more random response, while a lower temperature value will result in a more predictable response.\n","\n","- **`top_p`**: This parameter **controls the diversity of the generated response by establishing a cumulative probability cutoff for token selection**. A higher value of top_p will result in a more diverse response, while a lower value will result in a less diverse response.\n","\n","- **`repeat_penalty`**: This parameter **controls the penalty for repeating tokens in the generated response**. A higher value of repeat_penalty will result in a lower probability of repeating tokens, while a lower value will result in a higher probability of repeating tokens.\n","\n","- **`top_k`**: This parameter **controls the maximum number of most-likely next tokens to consider** when generating the response at each step.\n","\n","- **`stop`**: This parameter is a **list of tokens that are used to dynamically stop response generation** whenever the tokens in the list are encountered.\n","\n","- **`echo`**: This parameter **controls whether the input (prompt) to the model should be returned** in the model response.\n","\n","- **`seed`**: This parameter **specifies a seed value that helps replicate results**.\n"]},{"cell_type":"markdown","id":"CHwEJ-hYjZyw","metadata":{"id":"CHwEJ-hYjZyw"},"source":["### Utility function"]},{"cell_type":"code","execution_count":null,"id":"OWcEelJkO0uq","metadata":{"id":"OWcEelJkO0uq"},"outputs":[],"source":["# defining a function to parse the JSON output from the model\n","def extract_json_data(json_str):\n","    try:\n","        # Find the indices of the opening and closing curly braces\n","        json_start = json_str.find('{')\n","        json_end = json_str.rfind('}')\n","\n","        if json_start != -1 and json_end != -1:\n","            extracted_sentiment = json_str[json_start:json_end + 1]  # Extract the JSON object\n","            data_dict = json.loads(extracted_sentiment)\n","            return data_dict\n","        else:\n","            print(f\"Warning: JSON object not found in response: {json_str}\")\n","            return {}\n","    except json.JSONDecodeError as e:\n","        print(f\"Error parsing JSON: {e}\")\n","        return {}"]},{"cell_type":"markdown","id":"BhARt3BUmHJA","metadata":{"id":"BhARt3BUmHJA"},"source":["## 1. Sentiment Analysis (Llama)"]},{"cell_type":"code","execution_count":null,"id":"ifE2NALEmysV","metadata":{"id":"ifE2NALEmysV"},"outputs":[],"source":["# creating a copy of the data\n","data_1 = data.copy()"]},{"cell_type":"code","execution_count":null,"id":"NaOpXQfumHJC","metadata":{"id":"NaOpXQfumHJC"},"outputs":[],"source":["# defining the instructions for the model\n","instruction_1 = \"\"\"\n","    You are an AI analyzing restaurant reviews. Classify the sentiment of the provided review into the following categories:\n","    - Positive\n","    - Negative\n","    - Neutral\n","\"\"\""]},{"cell_type":"code","execution_count":null,"id":"367lfafHmHJC","metadata":{"id":"367lfafHmHJC"},"outputs":[],"source":["data_1['model_response'] = data_1['review_full'].apply(lambda x: generate_llama_response(instruction_1, x))"]},{"cell_type":"code","execution_count":null,"id":"76Ym659-m7yI","metadata":{"id":"76Ym659-m7yI"},"outputs":[],"source":["data_1['model_response'].head()"]},{"cell_type":"code","execution_count":null,"id":"832fdf50","metadata":{"id":"832fdf50"},"outputs":[],"source":["data.shape"]},{"cell_type":"code","execution_count":null,"id":"iQEDE21ymHJD","metadata":{"id":"iQEDE21ymHJD"},"outputs":[],"source":["i = 2\n","print(data_1.loc[i, 'review_full'])"]},{"cell_type":"code","execution_count":null,"id":"Dzuc2gsu4gCZ","metadata":{"id":"Dzuc2gsu4gCZ"},"outputs":[],"source":["print(data_1.loc[i, 'model_response'])"]},{"cell_type":"code","execution_count":null,"id":"_s0tz3CmmHJD","metadata":{"id":"_s0tz3CmmHJD"},"outputs":[],"source":["def extract_sentiment(model_response):\n","    if 'positive' in model_response.lower():\n","        return 'Positive'\n","    elif 'negative' in model_response.lower():\n","        return 'Negative'\n","    elif 'neutral' in model_response.lower():\n","        return 'Neutral'"]},{"cell_type":"code","execution_count":null,"id":"_ie4vWp_mHJE","metadata":{"id":"_ie4vWp_mHJE"},"outputs":[],"source":["# applying the function to the model response\n","data_1['sentiment'] = data_1['model_response'].apply(extract_sentiment)\n","data_1['sentiment'].head()"]},{"cell_type":"code","execution_count":null,"id":"Wdx85PqRf1H7","metadata":{"id":"Wdx85PqRf1H7"},"outputs":[],"source":["data_1['sentiment'].value_counts()"]},{"cell_type":"code","execution_count":null,"id":"BAajLpLOmHJF","metadata":{"id":"BAajLpLOmHJF"},"outputs":[],"source":["final_data_1 = data_1.drop(['model_response'], axis=1)\n","final_data_1.head()"]},{"cell_type":"markdown","id":"sq1Aq8BXajfg","metadata":{"id":"sq1Aq8BXajfg"},"source":["## 1. Sentiment Analysis (Mistral)"]},{"cell_type":"code","execution_count":null,"id":"ScqJfjzyajgD","metadata":{"id":"ScqJfjzyajgD"},"outputs":[],"source":["# creating a copy of the data\n","data_1 = data.copy()"]},{"cell_type":"markdown","id":"-rnRNMvh1IUL","metadata":{"id":"-rnRNMvh1IUL"},"source":["**We are going to use an instruction-tuned Mistral model. Hence, the format of the input to the model varies from that of Llama.**"]},{"cell_type":"code","execution_count":null,"id":"o1NHOv7fa5LU","metadata":{"id":"o1NHOv7fa5LU"},"outputs":[],"source":["#Defining the response funciton for Task 1.\n","def response_1(prompt,review):\n","    model_output = llm(\n","      f\"\"\"\n","      Q: {prompt}\n","      Review: {review}\n","      A:\n","      \"\"\",\n","      max_tokens=32,\n","      stop=[\"Q:\", \"\\n\"],\n","      temperature=0.01,\n","      echo=False,\n","    )\n","\n","    temp_output = model_output[\"choices\"][0][\"text\"]\n","\n","    return temp_output"]},{"cell_type":"code","execution_count":null,"id":"kOCUHdAiajgE","metadata":{"id":"kOCUHdAiajgE"},"outputs":[],"source":["# defining the instructions for the model\n","instruction_1 = \"\"\"\n","    You are an AI analyzing restaurant reviews. Classify the sentiment of the provided review into the following categories:\n","    - Positive\n","    - Negative\n","    - Neutral\n","\"\"\""]},{"cell_type":"code","execution_count":null,"id":"m4c3-lWwajgF","metadata":{"id":"m4c3-lWwajgF"},"outputs":[],"source":["data_1['model_response'] = data_1['review_full'].apply(lambda x: response_1(instruction_1, x))"]},{"cell_type":"code","execution_count":null,"id":"ZD036AJSajgG","metadata":{"id":"ZD036AJSajgG"},"outputs":[],"source":["data_1['model_response'].head()"]},{"cell_type":"code","execution_count":null,"id":"B4xz7jZmajgH","metadata":{"id":"B4xz7jZmajgH"},"outputs":[],"source":["i = 2\n","print(data_1.loc[i, 'review_full'])"]},{"cell_type":"code","execution_count":null,"id":"fsAehjb6ajgI","metadata":{"id":"fsAehjb6ajgI"},"outputs":[],"source":["print(data_1.loc[i, 'model_response'])"]},{"cell_type":"code","execution_count":null,"id":"Bckp7sqXajgI","metadata":{"id":"Bckp7sqXajgI"},"outputs":[],"source":["def extract_sentiment(model_response):\n","    if 'positive' in model_response.lower():\n","        return 'Positive'\n","    elif 'negative' in model_response.lower():\n","        return 'Negative'\n","    elif 'neutral' in model_response.lower():\n","        return 'Neutral'"]},{"cell_type":"code","execution_count":null,"id":"RzZQ9ZZTajgJ","metadata":{"id":"RzZQ9ZZTajgJ"},"outputs":[],"source":["# applying the function to the model response\n","data_1['sentiment'] = data_1['model_response'].apply(extract_sentiment)\n","data_1['sentiment'].head()"]},{"cell_type":"code","execution_count":null,"id":"t4yh3oF1ajgK","metadata":{"id":"t4yh3oF1ajgK"},"outputs":[],"source":["data_1['sentiment'].value_counts()"]},{"cell_type":"code","execution_count":null,"id":"2mgE55M2ajgL","metadata":{"id":"2mgE55M2ajgL"},"outputs":[],"source":["final_data_1 = data_1.drop(['model_response'], axis=1)\n","final_data_1.head()"]},{"cell_type":"markdown","id":"ixmkBFZjh3Uu","metadata":{"id":"ixmkBFZjh3Uu"},"source":["## 2. Sentiment Analysis and Returning Structured Output (Llama)"]},{"cell_type":"code","execution_count":null,"id":"Mgee5PGLnhNr","metadata":{"id":"Mgee5PGLnhNr"},"outputs":[],"source":["# creating a copy of the data\n","data_2 = data.copy()"]},{"cell_type":"code","execution_count":null,"id":"kjDHDEs0cX5U","metadata":{"id":"kjDHDEs0cX5U"},"outputs":[],"source":["# defining the instructions for the model\n","instruction_2 = \"\"\"\n","    You are an AI analyzing restaurant reviews. Classify the sentiment of the provided review into the following categories:\n","    - Positive\n","    - Negative\n","    - Neutral\n","\n","    Format the output as a JSON object with a single key-value pair as shown below:\n","    {\"sentiment\": \"your_sentiment_prediction\"}\n","\"\"\""]},{"cell_type":"code","execution_count":null,"id":"SqtxeTOnh3VE","metadata":{"id":"SqtxeTOnh3VE"},"outputs":[],"source":["data_2['model_response'] = data_2['review_full'].apply(lambda x: generate_llama_response(instruction_2, x))"]},{"cell_type":"code","execution_count":null,"id":"P2Zf6SsN4bsJ","metadata":{"id":"P2Zf6SsN4bsJ"},"outputs":[],"source":["data_2['model_response'].head()"]},{"cell_type":"code","execution_count":null,"id":"Sj9Kw8LLh3VF","metadata":{"id":"Sj9Kw8LLh3VF"},"outputs":[],"source":["i = 2\n","print(data_2.loc[i, 'review_full'])"]},{"cell_type":"code","execution_count":null,"id":"Bxv3poEE4n3n","metadata":{"id":"Bxv3poEE4n3n"},"outputs":[],"source":["print(data_2.loc[i, 'model_response'])"]},{"cell_type":"code","execution_count":null,"id":"A6Zo_YDch3VG","metadata":{"id":"A6Zo_YDch3VG"},"outputs":[],"source":["# applying the function to the model response\n","data_2['model_response_parsed'] = data_2['model_response'].apply(extract_json_data)\n","data_2['model_response_parsed'].head()"]},{"cell_type":"code","execution_count":null,"id":"qFPR8vPAh3VH","metadata":{"id":"qFPR8vPAh3VH"},"outputs":[],"source":["model_response_parsed_df_2 = pd.json_normalize(data_2['model_response_parsed'])\n","model_response_parsed_df_2.head()"]},{"cell_type":"code","execution_count":null,"id":"NX-zy5BTh3VH","metadata":{"id":"NX-zy5BTh3VH"},"outputs":[],"source":["data_with_parsed_model_output_2 = pd.concat([data_2, model_response_parsed_df_2], axis=1)\n","data_with_parsed_model_output_2.head()"]},{"cell_type":"code","execution_count":null,"id":"6hiEw_Znh3VI","metadata":{"id":"6hiEw_Znh3VI"},"outputs":[],"source":["final_data_2 = data_with_parsed_model_output_2.drop(['model_response','model_response_parsed'], axis=1)\n","final_data_2.head()"]},{"cell_type":"code","execution_count":null,"id":"xuZttnsMos6g","metadata":{"id":"xuZttnsMos6g"},"outputs":[],"source":["final_data_2['sentiment'].value_counts()"]},{"cell_type":"markdown","id":"HslGURoah3VI","metadata":{"id":"HslGURoah3VI"},"source":["## 3. Identifying Overall Sentiment and Sentiment of Aspects of the Experience (Llama)"]},{"cell_type":"code","execution_count":null,"id":"MZcG8ygIn2qy","metadata":{"id":"MZcG8ygIn2qy"},"outputs":[],"source":["# creating a copy of the data\n","data_3 = data.copy()"]},{"cell_type":"code","execution_count":null,"id":"YhdIDYq4lf3C","metadata":{"id":"YhdIDYq4lf3C"},"outputs":[],"source":["# defining the instructions for the model\n","instruction_3 = \"\"\"\n","    You are an AI analyzing restaurant reviews. Classify the overall sentiment of the provided review into the following categories:\n","    - \"Positive\"\n","    - \"Negative\"\n","    - \"Neutral\"\n","\n","    Once that is done, check for a mention of the following aspects in the review and classify the sentiment of each aspect as \"Positive\", \"Negative\", or \"Neutral\":\n","    1. \"Food Quality\"\n","    2. \"Service\"\n","    3. \"Ambience\"\n","\n","    Output the overall sentiment and sentiment for each category in a JSON format with the following keys:\n","    {\n","        \"Overall\": \"your_sentiment_prediction\",\n","        \"Food Quality\": \"your_sentiment_prediction\",\n","        \"Service\": \"your_sentiment_prediction\",\n","        \"Ambience\": \"your_sentiment_prediction\"\n","    }\n","\n","    In case one of the three aspects is not mentioned in the review, set \"Not Applicable\" (including quotes) for the corresponding JSON key value.\n","    Only return the JSON, do not return any other information.\n","\"\"\""]},{"cell_type":"code","execution_count":null,"id":"vOmka93ilf3O","metadata":{"id":"vOmka93ilf3O"},"outputs":[],"source":["data_3['model_response'] = data_3['review_full'].apply(lambda x: generate_llama_response(instruction_3, x))"]},{"cell_type":"code","execution_count":null,"id":"IwAEYkStbUjv","metadata":{"id":"IwAEYkStbUjv"},"outputs":[],"source":["data_3['model_response'].head()"]},{"cell_type":"code","execution_count":null,"id":"FnfnhInbup2A","metadata":{"id":"FnfnhInbup2A"},"outputs":[],"source":["i = 2\n","print(data_3.loc[i, 'review_full'])"]},{"cell_type":"code","execution_count":null,"id":"tAqbJ5Hs4v-A","metadata":{"id":"tAqbJ5Hs4v-A"},"outputs":[],"source":["print(data_3.loc[i, 'model_response'])"]},{"cell_type":"code","execution_count":null,"id":"1t7hUgimunU5","metadata":{"id":"1t7hUgimunU5"},"outputs":[],"source":["# applying the function to the model response\n","data_3['model_response_parsed'] = data_3['model_response'].apply(extract_json_data)\n","data_3['model_response_parsed'].head()"]},{"cell_type":"code","execution_count":null,"id":"sX_m53eLunVA","metadata":{"id":"sX_m53eLunVA"},"outputs":[],"source":["model_response_parsed_df_3 = pd.json_normalize(data_3['model_response_parsed'])\n","model_response_parsed_df_3.head()"]},{"cell_type":"code","execution_count":null,"id":"B37cFr6punVB","metadata":{"id":"B37cFr6punVB"},"outputs":[],"source":["data_with_parsed_model_output_3 = pd.concat([data_3, model_response_parsed_df_3], axis=1)\n","data_with_parsed_model_output_3.head()"]},{"cell_type":"code","execution_count":null,"id":"kMDwOWVPunVB","metadata":{"id":"kMDwOWVPunVB"},"outputs":[],"source":["final_data_3 = data_with_parsed_model_output_3.drop(['model_response','model_response_parsed'], axis=1)\n","final_data_3.head()"]},{"cell_type":"code","execution_count":null,"id":"gkyB71hC22kS","metadata":{"id":"gkyB71hC22kS"},"outputs":[],"source":["final_data_3['Overall'].value_counts()"]},{"cell_type":"code","execution_count":null,"id":"uQ__aM1Hcy00","metadata":{"id":"uQ__aM1Hcy00"},"outputs":[],"source":["final_data_3['Food Quality'].value_counts()"]},{"cell_type":"code","execution_count":null,"id":"Ah3IRNDTcyxO","metadata":{"id":"Ah3IRNDTcyxO"},"outputs":[],"source":["final_data_3['Service'].value_counts()"]},{"cell_type":"code","execution_count":null,"id":"hPQZOYwicyui","metadata":{"id":"hPQZOYwicyui"},"outputs":[],"source":["final_data_3['Ambience'].value_counts()"]},{"cell_type":"markdown","id":"Mf4lta2PbHS4","metadata":{"id":"Mf4lta2PbHS4"},"source":["## 3. Identifying Overall Sentiment and Sentiment of Aspects of the Experience (Mistral)"]},{"cell_type":"code","execution_count":null,"id":"ZWwS7SIpbHTb","metadata":{"id":"ZWwS7SIpbHTb"},"outputs":[],"source":["# creating a copy of the data\n","data_3 = data.copy()"]},{"cell_type":"code","execution_count":null,"id":"6N4lVvxkbz7Y","metadata":{"id":"6N4lVvxkbz7Y"},"outputs":[],"source":["def response_2(prompt,review,sentiment):\n","    model_output = llm(\n","      f\"\"\"\n","      Q: {prompt}\n","      review: {review}\n","      sentiment: {sentiment}\n","      A:\n","      \"\"\",\n","      max_tokens=64,\n","      stop=[\"Q:\", \"\\n\"],\n","      temperature=0.01,\n","      echo=False,\n","    )\n","\n","    temp_output = model_output[\"choices\"][0][\"text\"]\n","    final_output = temp_output[temp_output.index('{'):]\n","\n","    return final_output"]},{"cell_type":"markdown","id":"us5pXLe30NaB","metadata":{"id":"us5pXLe30NaB"},"source":["**Note:** We have already predicted the sentiment of the review. We can use this information while designing the prompt for this task. This way, it will reduce the computational complexity.\n","\n","The sentiment is stored in the 'final_data_1' dataframe which is from the TASK 1."]},{"cell_type":"code","execution_count":null,"id":"vmP6pXJQbHTc","metadata":{"id":"vmP6pXJQbHTc"},"outputs":[],"source":["# defining the instructions for the model\n","instruction_3 = \"\"\"\n","    You are provided a review and it's sentiment.\n","\n","    Instructions:\n","    Classify the sentiment of each aspect as either of \"Positive\", \"Negative\", or \"Neutral\" only and not any other for the given review:\n","    1. \"Food Quality\"\n","    2. \"Service\"\n","    3. \"Ambience\"\n","    In case one of the three aspects is not mentioned in the review, return \"Not Applicable\" (including quotes) for the corresponding JSON key value.\n","    Return the output in the format {\"Overall\": given sentiment input,\"Food Quality\": \"your_sentiment_prediction\",\"Service\": \"your_sentiment_prediction\",\"Ambience\": \"your_sentiment_prediction\"}\n","\n","\"\"\""]},{"cell_type":"code","execution_count":null,"id":"mBQruWc9bHTd","metadata":{"id":"mBQruWc9bHTd"},"outputs":[],"source":["data_3['model_response'] = final_data_1[['review_full','sentiment']].apply(lambda x: response_2(instruction_3, x[0],x[1]),axis=1)"]},{"cell_type":"code","execution_count":null,"id":"CvjebhnZbHTe","metadata":{"id":"CvjebhnZbHTe"},"outputs":[],"source":["data_3['model_response'].values"]},{"cell_type":"code","execution_count":null,"id":"r-t5e6gMbHTf","metadata":{"id":"r-t5e6gMbHTf"},"outputs":[],"source":["i = 2\n","print(data_3.loc[i, 'review_full'])"]},{"cell_type":"code","execution_count":null,"id":"h9yyFpQHbHTg","metadata":{"id":"h9yyFpQHbHTg"},"outputs":[],"source":["print(data_3.loc[i, 'model_response'])"]},{"cell_type":"code","execution_count":null,"id":"MuvmCV_DbHTh","metadata":{"id":"MuvmCV_DbHTh"},"outputs":[],"source":["# applying the function to the model response\n","data_3['model_response_parsed'] = data_3['model_response'].apply(extract_json_data)\n","data_3['model_response_parsed']"]},{"cell_type":"code","execution_count":null,"id":"D2T6_J8vbHTi","metadata":{"id":"D2T6_J8vbHTi"},"outputs":[],"source":["model_response_parsed_df_3 = pd.json_normalize(data_3['model_response_parsed'])\n","model_response_parsed_df_3"]},{"cell_type":"code","execution_count":null,"id":"F_KjQ3sXqAEj","metadata":{"id":"F_KjQ3sXqAEj"},"outputs":[],"source":["model_response_parsed_df_3 = model_response_parsed_df_3.apply(lambda x: x.astype(str).str.lower())"]},{"cell_type":"code","execution_count":null,"id":"5fudlsBnbHTj","metadata":{"id":"5fudlsBnbHTj"},"outputs":[],"source":["data_with_parsed_model_output_3 = pd.concat([data_3, model_response_parsed_df_3], axis=1)\n","data_with_parsed_model_output_3.head()"]},{"cell_type":"code","execution_count":null,"id":"v6Ktnid1bHTk","metadata":{"id":"v6Ktnid1bHTk"},"outputs":[],"source":["final_data_3 = data_with_parsed_model_output_3.drop(['model_response','model_response_parsed'], axis=1)\n","final_data_3.head()"]},{"cell_type":"code","execution_count":null,"id":"8dm8LimPbHTl","metadata":{"id":"8dm8LimPbHTl"},"outputs":[],"source":["final_data_3['Overall'].value_counts()"]},{"cell_type":"code","execution_count":null,"id":"79rgJ_pObHTm","metadata":{"id":"79rgJ_pObHTm"},"outputs":[],"source":["final_data_3['Food Quality'].value_counts()"]},{"cell_type":"markdown","id":"a8IllrLC0u1a","metadata":{"id":"a8IllrLC0u1a"},"source":["**Note:** One of the sentiment is 'if not exceptional'. This is most likely positive."]},{"cell_type":"code","execution_count":null,"id":"-a8rLEt3bHTm","metadata":{"id":"-a8rLEt3bHTm"},"outputs":[],"source":["final_data_3['Service'].value_counts()"]},{"cell_type":"code","execution_count":null,"id":"-JCcAI2UbHTn","metadata":{"id":"-JCcAI2UbHTn"},"outputs":[],"source":["final_data_3['Ambience'].value_counts()"]},{"cell_type":"markdown","id":"RxpHCNQeh3VL","metadata":{"id":"RxpHCNQeh3VL"},"source":["## 4. Identifying Overall Sentiment, Sentiment of Aspects of the Experience, and the Liked/Disliked Features of the Different Aspects of the Experience (Llama)"]},{"cell_type":"code","execution_count":null,"id":"VtLikOc_vRsd","metadata":{"id":"VtLikOc_vRsd"},"outputs":[],"source":["# creating a copy of the data\n","data_4 = data.copy()"]},{"cell_type":"code","execution_count":null,"id":"iJVySI-LcX3X","metadata":{"id":"iJVySI-LcX3X"},"outputs":[],"source":["# defining the instructions for the model\n","instruction_4 = \"\"\"\n","    You are an AI tasked with analyzing restaurant reviews. Your goal is to classify the overall sentiment of the provided review into the following categories:\n","        - Positive\n","        - Negative\n","        - Neutral\n","\n","    Subsequently, assess the sentiment of specific aspects mentioned in the review, namely:\n","        1. Food quality\n","        2. Service\n","        3. Ambience\n","\n","    Further, identify liked and/or disliked features associated with each aspect in the review.\n","\n","    Return the output in the specified JSON format, ensuring consistency and handling missing values appropriately:\n","\n","    {\n","        \"Overall\": \"your_sentiment_prediction\",\n","        \"Food Quality\": \"your_sentiment_prediction\",\n","        \"Service\": \"your_sentiment_prediction\",\n","        \"Ambience\": \"your_sentiment_prediction\",\n","        \"Food Quality Features\": [\"liked/disliked features\"],\n","        \"Service Features\": [\"liked/disliked features\"],\n","        \"Ambience Features\": [\"liked/disliked features\"]\n","    }\n","\n","    The sentiment prediction for Overall, Food Quality, Service, and Ambience should be one of \"Positive\", \"Negative\", or \"Neutral\" only.\n","    In case one of the three aspects is not mentioned in the review, set \"Not Applicable\" (including quotes) in the corresponding JSON key value for the sentiment.\n","    In case there are no liked/disliked features for a particular aspect, assign an empty list in the corresponding JSON key value for the aspect.\n","    Only return the JSON, do NOT return any other text or information.\n","\"\"\""]},{"cell_type":"code","execution_count":null,"id":"pM2Vrx5svRsm","metadata":{"id":"pM2Vrx5svRsm"},"outputs":[],"source":["data_4['model_response'] = data_4['review_full'].apply(lambda x: generate_llama_response(instruction_4, x).replace('\\n', ''))"]},{"cell_type":"code","execution_count":null,"id":"pYLMMMdLvRsm","metadata":{"id":"pYLMMMdLvRsm"},"outputs":[],"source":["i = 2\n","print(data_4.loc[i, 'review_full'])"]},{"cell_type":"code","execution_count":null,"id":"fz6EQKwd4_qb","metadata":{"id":"fz6EQKwd4_qb"},"outputs":[],"source":["print(data_4.loc[i, 'model_response'])"]},{"cell_type":"code","execution_count":null,"id":"qLyEyL4avRsm","metadata":{"id":"qLyEyL4avRsm"},"outputs":[],"source":["# applying the function to the model response\n","data_4['model_response_parsed'] = data_4['model_response'].apply(extract_json_data)\n","data_4['model_response_parsed'].head()"]},{"cell_type":"code","execution_count":null,"id":"z22aZcPx_NnQ","metadata":{"id":"z22aZcPx_NnQ"},"outputs":[],"source":["data_4[data_4.model_response_parsed == {}]"]},{"cell_type":"markdown","id":"h6GGBy0B_SNK","metadata":{"id":"h6GGBy0B_SNK"},"source":["- There are three model responses that the JSON parser function could not parse\n","- We'll manually add the values for these three responses"]},{"cell_type":"code","execution_count":null,"id":"iO0DtzLh_R1_","metadata":{"id":"iO0DtzLh_R1_"},"outputs":[],"source":["print(data_4.loc[3, 'model_response'])"]},{"cell_type":"code","execution_count":null,"id":"ZGRD2IVJ_pjt","metadata":{"id":"ZGRD2IVJ_pjt"},"outputs":[],"source":["print(data_4.loc[6, 'model_response'])"]},{"cell_type":"code","execution_count":null,"id":"zIlXqANQ__33","metadata":{"id":"zIlXqANQ__33"},"outputs":[],"source":["print(data_4.loc[7, 'model_response'])"]},{"cell_type":"code","execution_count":null,"id":"4mKK7kPP__vS","metadata":{"id":"4mKK7kPP__vS"},"outputs":[],"source":["upd_val_1 = {\n","    \"Overall\": \"Positive\",\n","    \"Food Quality\": \"Positive\",\n","    \"Service\": \"Positive\",\n","    \"Ambience\": \"Not Applicable\",\n","    \"Food Quality Features\": [],\n","    \"Service Features\": [\"excellent service\"],\n","    \"Ambience Features\": []\n","}\n","\n","upd_val_2 = {\n","    \"Overall\": \"Neutral\",\n","    \"Food Quality\": \"Neutral\",\n","    \"Service\": \"Neutral\",\n","    \"Ambience\": \"Not Applicable\",\n","    \"Food Quality Features\": [\"well prepared\"],\n","    \"Service Features\": [\"slow and inattentive\"],\n","    \"Ambience Features\": [\"interior is friendly\", \"not intimidating\"]\n","}\n","\n","upd_val_3 = {\n","    \"Overall\": \"Neutral\",\n","    \"Food Quality\": \"Positive\",\n","    \"Service\": \"Negative\",\n","    \"Ambience\": \"Positive\",\n","    \"Food Quality Features\": [\"Some tasty, others average\"],\n","    \"Service Features\": [\"Attentive staff\", \"Slow service\"],\n","    \"Ambience Features\": []\n","}\n","\n","# defining the list of indices to update\n","idx_list = [3,6,7]\n","data_4.loc[idx_list, 'model_response_parsed'] = [upd_val_1, upd_val_2, upd_val_3]"]},{"cell_type":"markdown","id":"96TJoxhWhpCs","metadata":{"id":"96TJoxhWhpCs"},"source":["**Note**: The values model responses that cannot be parsed correctly by the JSON parser function may vary with execution due to the randomness associated with LLMs. Kindly update as observed when run in your system."]},{"cell_type":"code","execution_count":null,"id":"-WlHzvoHvRsm","metadata":{"id":"-WlHzvoHvRsm"},"outputs":[],"source":["model_response_parsed_df_4 = pd.json_normalize(data_4['model_response_parsed'])\n","model_response_parsed_df_4.head()"]},{"cell_type":"code","execution_count":null,"id":"j6i2peyLvRsm","metadata":{"id":"j6i2peyLvRsm"},"outputs":[],"source":["data_with_parsed_model_output_4 = pd.concat([data_4, model_response_parsed_df_4], axis=1)\n","data_with_parsed_model_output_4.head()"]},{"cell_type":"code","execution_count":null,"id":"Hu8LyWsZvRsm","metadata":{"id":"Hu8LyWsZvRsm"},"outputs":[],"source":["final_data_4 = data_with_parsed_model_output_4.drop(['model_response','model_response_parsed'], axis=1)\n","final_data_4.head()"]},{"cell_type":"code","execution_count":null,"id":"ZHNMqvjU2vUd","metadata":{"id":"ZHNMqvjU2vUd"},"outputs":[],"source":["final_data_4['Overall'].value_counts()"]},{"cell_type":"code","execution_count":null,"id":"2YgtXH5_eHuI","metadata":{"id":"2YgtXH5_eHuI"},"outputs":[],"source":["final_data_4['Food Quality'].value_counts()"]},{"cell_type":"code","execution_count":null,"id":"EZaowwqaeHuP","metadata":{"id":"EZaowwqaeHuP"},"outputs":[],"source":["final_data_4['Service'].value_counts()"]},{"cell_type":"code","execution_count":null,"id":"vEuXclkgeHuP","metadata":{"id":"vEuXclkgeHuP"},"outputs":[],"source":["final_data_4['Ambience'].value_counts()"]},{"cell_type":"markdown","id":"0k9WJ3bXxcdz","metadata":{"id":"0k9WJ3bXxcdz"},"source":["## 5. Identifying Overall Sentiment, Sentiment of Aspects of the Experience, Liked/Disliked Features of the Different Aspects of the Experience, and Sharing a Response (Llama)"]},{"cell_type":"code","execution_count":null,"id":"iMKm1ZM3xcd0","metadata":{"id":"iMKm1ZM3xcd0"},"outputs":[],"source":["# creating a copy of the data\n","data_5 = data.copy()"]},{"cell_type":"code","execution_count":null,"id":"AuaVtos0xcd0","metadata":{"id":"AuaVtos0xcd0"},"outputs":[],"source":["# defining the instructions for the model\n","instruction_5 = \"\"\"\n","    You are an AI analyzing restaurant reviews. Classify the overall sentiment of the provided review into the following categories:\n","    - \"Positive\"\n","    - \"Negative\"\n","    - \"Neutral\"\n","\n","    Once that is done, check for a mention of the following aspects in the review and clasify the sentiment of each aspect as positive, negative, or neutral:\n","    1. Food quality\n","    2. Service\n","    3. Ambience\n","\n","    Once that is done, look for liked and/or disliked features mentioned against each of the above aspects in the review and extract them.\n","\n","    Finally, draft a response for the customer based on the review. Start out with a thank you note and then add on to it as per the following:\n","    1. If the review is positive, mention that it would be great to have them again\n","    2. If the review is neutral, ask them for what the restaurant could have done better\n","    3. If the review is negative, apologive for the inconvenience and mention that we'll be looking into the points raised\n","\n","    Return the output in the specified JSON format, ensuring consistency and handling missing values appropriately Ensure that all values in the JSON are formatted as strings, and each element within the lists should be enclosed in double quotes:\n","\n","    {\n","        \"Overall\": \"your_sentiment_prediction\",\n","        \"Food Quality\": \"your_sentiment_prediction\",\n","        \"Service\": \"your_sentiment_prediction\",\n","        \"Ambience\": \"your_sentiment_prediction\",\n","        \"Food Quality Features\": [\"liked/disliked features\"],\n","        \"Service Features\": [\"liked/disliked features\"],\n","        \"Ambience Features\": [\"liked/disliked features\"],\n","        \"Response\": \"your_response_to_the_customer_review\",\n","    }\n","\n","    The sentiment prediction for Overall, Food Quality, Service, and Ambience should be one of \"Positive\", \"Negative\", or \"Neutral\" only.\n","    In case one of the three aspects is not mentioned in the review, set \"Not Applicable\" (including quotes) in the corresponding JSON key value for the sentiment.\n","    In case there are no liked/disliked features for a particular aspect, assign an empty list in the corresponding JSON key value for the aspect.\n","    Be polite and empathetic in the response to the customer review.\n","    Only return the JSON, do NOT return any other text or information.\n","\"\"\""]},{"cell_type":"code","execution_count":null,"id":"7rKhWLJNxcd0","metadata":{"id":"7rKhWLJNxcd0"},"outputs":[],"source":["data_5['model_response'] = data_5['review_full'].apply(lambda x: generate_llama_response(instruction_5, x))"]},{"cell_type":"code","execution_count":null,"id":"HIGcY1TIxcd0","metadata":{"id":"HIGcY1TIxcd0"},"outputs":[],"source":["i = 2\n","print(data_5.loc[i, 'review_full'])"]},{"cell_type":"code","execution_count":null,"id":"aalA4FCp5Fgj","metadata":{"id":"aalA4FCp5Fgj"},"outputs":[],"source":["print(data_5.loc[i, 'model_response'])"]},{"cell_type":"code","execution_count":null,"id":"H5SPJvmIxcd0","metadata":{"id":"H5SPJvmIxcd0"},"outputs":[],"source":["# applying the function to the model response\n","data_5['model_response_parsed'] = data_5['model_response'].apply(extract_json_data)\n","data_5['model_response_parsed'].head()"]},{"cell_type":"code","execution_count":null,"id":"xFVTS6sGxcd0","metadata":{"id":"xFVTS6sGxcd0"},"outputs":[],"source":["model_response_parsed_df_5 = pd.json_normalize(data_5['model_response_parsed'])\n","model_response_parsed_df_5.head()"]},{"cell_type":"code","execution_count":null,"id":"7e58393d","metadata":{"id":"7e58393d"},"outputs":[],"source":["model_response_parsed_df_5['Response'][0]"]},{"cell_type":"code","execution_count":null,"id":"gCyWWNcJxcd0","metadata":{"id":"gCyWWNcJxcd0"},"outputs":[],"source":["data_with_parsed_model_output_5 = pd.concat([data_5, model_response_parsed_df_5], axis=1)\n","data_with_parsed_model_output_5.head()"]},{"cell_type":"code","execution_count":null,"id":"QER0nBVBxcd1","metadata":{"id":"QER0nBVBxcd1"},"outputs":[],"source":["final_data_5 = data_with_parsed_model_output_5.drop(['model_response','model_response_parsed'], axis=1)\n","final_data_5.head()"]},{"cell_type":"code","execution_count":null,"id":"V2G6_2HUOlKp","metadata":{"id":"V2G6_2HUOlKp"},"outputs":[],"source":["final_data_5['Overall'].value_counts()"]},{"cell_type":"code","execution_count":null,"id":"_MQaFVC2OlKq","metadata":{"id":"_MQaFVC2OlKq"},"outputs":[],"source":["final_data_5['Food Quality'].value_counts()"]},{"cell_type":"code","execution_count":null,"id":"PICC0XMXOlKr","metadata":{"id":"PICC0XMXOlKr"},"outputs":[],"source":["final_data_5['Service'].value_counts()"]},{"cell_type":"code","execution_count":null,"id":"gZW3RYfmOlKr","metadata":{"id":"gZW3RYfmOlKr"},"outputs":[],"source":["final_data_5['Ambience'].value_counts()"]},{"cell_type":"markdown","id":"H3A46S7Tx_U6","metadata":{"id":"H3A46S7Tx_U6"},"source":["## Conclusions"]},{"cell_type":"markdown","id":"muFFmuCnyA43","metadata":{"id":"muFFmuCnyA43"},"source":["- We used an LLM to do multiple tasks, one stage at a time\n","    1. We first identified the overall sentiment of the review using the LLM\n","    2. We then identified the overall sentiment of the review and got the output in a structured format from the LLM for ease-of-access\n","    3. Next, we identified the overall sentiment of the review as well as sentiment of specific aspects of the experience\n","    4. Next, in addition to the overall sentiment of the review as well as sentiment of specific aspects of the experience, we also identified the liked/disliked features of the different aspects of the experience\n","    5. Finally, in addition to all the above, we also got a response we can share with the customer based on their review\n","\n","- One can manually label the data (overall sentiment and sentiments of different aspects) and then compare the model's output with the same to get a quantitative measure of the models performance.\n","\n","- To try and improve the model performance, one can try the following:\n","    1. Update the prompt\n","    2. Update the model parameters (`temparature`, `top_p`, ...)\n","\n"]},{"cell_type":"markdown","id":"JJztOYrhx87T","metadata":{"id":"JJztOYrhx87T"},"source":["___"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["G-jLkpBYdP89","xClk0SOxdU_s","MzSKXh2LsOvd","mgGZFBqvdX3_","b8pDl8uVKR2W","mv_4wV7dTNqQ","H-51wMmpGzcr","jbaduRVymY3v","oWvf3R3An5K4","VVXK7vYfmdkL","CHwEJ-hYjZyw","BhARt3BUmHJA","sq1Aq8BXajfg","ixmkBFZjh3Uu","HslGURoah3VI","Mf4lta2PbHS4","RxpHCNQeh3VL","0k9WJ3bXxcdz","H3A46S7Tx_U6"],"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.13.5"}},"nbformat":4,"nbformat_minor":5}